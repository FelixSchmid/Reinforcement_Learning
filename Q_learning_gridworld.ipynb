{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q_learning_gridworld.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelixSchmid/Reinforcement_Learning/blob/master/Q_learning_gridworld.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W--cwMOLk_AR"
      },
      "source": [
        "# Gridworld example with Q-learning and Sarsa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V2T7CRxdk_AV",
        "colab": {}
      },
      "source": [
        "# importing the necessary libraries\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1PhA8ozjk_AZ"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=18q7KL4aV6McMtaid_1Let2aGkw6d4QYn\" width=45%>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GvetlIhpk_Aa",
        "colab": {}
      },
      "source": [
        "class GridWorld:\n",
        "    \"\"\"\n",
        "    The environment: (see image)\n",
        "    * cells: the agent can step on a cell. There is exactly one cell to start from.\n",
        "    This is the top left corner. There is one terminal cell where the walking ends, \n",
        "    the agent can not leave it (blue).\n",
        "    * obstacles: there are cells where the agent can not step. (gray)\n",
        "    * agent: it can move from one cell to an other neighboring cell. \n",
        "    Possible directions: up, down, left, right. Each transition happens with probability 1.\n",
        "    * reward: after each transition the agent receives -1 point. In the terminal cell, no reward\n",
        "    received anymore.\n",
        "    \"\"\"\n",
        "    def __init__(self, size, start_cell, obstacles, terminating_state):\n",
        "        self.size = size\n",
        "        self.start = start_cell\n",
        "        self.obstacles = obstacles\n",
        "        self.termin = terminating_state\n",
        "        self.current_cell = self.start\n",
        "    \n",
        "    def reset(self):\n",
        "        # ----- reset the current cell to the start cell to start again -----\n",
        "        self.current_cell = self.start\n",
        "    \n",
        "    def transition(self, cell, action):\n",
        "        # cell = (row, column) indices\n",
        "        # action: 0 left, 1 up, 2 right, 3 down\n",
        "        # returns: What will be the next state\n",
        "        # Take care of the borders of the grid!\n",
        "\n",
        "        r_current = cell[0]\n",
        "        c_current = cell[1]\n",
        "        \n",
        "        # left\n",
        "        if action == 0:\n",
        "          cell = (r_current,c_current-1)\n",
        "        # up\n",
        "        if action == 1:\n",
        "          cell = (r_current-1,c_current)\n",
        "        # right\n",
        "        if action == 2:\n",
        "          cell = (r_current,c_current+1)\n",
        "        # down\n",
        "        if action == 3:\n",
        "          cell = (r_current+1,c_current)\n",
        "\n",
        "        if (cell[0], cell[1]) in self.obstacles:\n",
        "          # undo step if we hit an obst.\n",
        "          cell = (r_current,c_current)\n",
        "\n",
        "        if cell[0] < 0 \\\n",
        "             or cell[0] > self.size[0] -1 \\\n",
        "             or cell[1] < 0  \\\n",
        "             or cell[1] > self.size[1] -1 : \n",
        "          # undo steps if we left the board\n",
        "          cell = (r_current, c_current)\n",
        "        \n",
        "        # update the current_cell the step\n",
        "        self.current_cell = cell\n",
        "        \n",
        "        return cell\n",
        "\n",
        "\n",
        "    def reward(self, cell, action):\n",
        "        # ----- RETURN REWARD -----\n",
        "        # -1 if not in the terminal state\n",
        "        cell_state = cell\n",
        "        if self.transition(cell, action) != self.termin:\n",
        "          reward = -1\n",
        "        else:\n",
        "          reward = 0\n",
        "        # we only want to know the reward of a pot. transition\n",
        "        # so we undo the action which is done within def transition that we call\n",
        "        # for doing the transition, we need to call transition alone\n",
        "        # probably there is a more elegant solution\n",
        "        self.current_cell = cell_state\n",
        "        return reward\n",
        "\n",
        "    def in_terminal(self):\n",
        "        return self.current_cell == self.termin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_SaVJnPMk_Ad",
        "colab": {}
      },
      "source": [
        "class QLearning:\n",
        "    \"\"\"\n",
        "    In this class you can implement the Q-learning algorithm.\n",
        "    The algorithm will run trajectories in the environment (grid world)\n",
        "    and according to the transitions ()\n",
        "    \"\"\"\n",
        "    def __init__(self, gridworld, gamma, alpha, episodes):\n",
        "        self.gridworld = gridworld\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.episodes = episodes\n",
        "        # create table\n",
        "        size = gridworld.size\n",
        "        # create a numpy matrix for storing the q-values for each actions and states\n",
        "        self.q_table =  self.q_table = np.zeros((4,) + size)   \n",
        "        # epsilon greedy\n",
        "        self.eps = 0.9\n",
        "        self.episode = 0\n",
        "        # performance summary\n",
        "        self.sum_rewards = []\n",
        "        self.path = []\n",
        "    \n",
        "    def update(self, cell, action, reward, next_cell):\n",
        "        r_t, c_t = cell  # current state\n",
        "        r_tp1, c_tp1 = next_cell  # next state\n",
        "        # the update rule for q-learning\n",
        "        q_current_step = self.q_table[action, r_t, c_t] \n",
        "        q_next_step = max(self.q_table[:, r_tp1, c_tp1])\n",
        "        error_term = reward + self.gamma * q_next_step - q_current_step\n",
        "        self.q_table[action, r_t, c_t] = q_current_step + self.alpha * (error_term)\n",
        "    \n",
        "    def choose_action(self, cell):\n",
        "        r, c = cell\n",
        "        # choose the next action accroding to epsilon-greedy \n",
        "        if np.random.random() > (1 - self.eps):\n",
        "            action = np.argmax(self.q_table[:, r, c])\n",
        "        else:\n",
        "            action = np.random.randint(low=0, high=4)\n",
        "        return action\n",
        "    \n",
        "    def anneal_epsilon(self):\n",
        "        # The algo smoothly shifts from exploration to exploitation.\n",
        "        self.eps = max(0, self.eps * (1 - self.episode / self.episodes * 1.5))\n",
        "    \n",
        "    def one_episode(self):  # plays an episode\n",
        "        # This function is responsible for running the agent \n",
        "        # for one episode.\n",
        "        # During each transition, the Q-function is updated.\n",
        "        cntr = 0  # counter to avoid infinite loops when the agent stucks in the grid and can not reach the terminal state\n",
        "        #  reset the gridworld \n",
        "        self.gridworld.reset()\n",
        "        # append zero at the end of sum_rewards \n",
        "        self.sum_rewards.append(0)\n",
        "        # cycle until termination (end of the current episode) or an upper limit (e.g. 5000)\n",
        "        while not self.gridworld.in_terminal() and cntr < 5000:\n",
        "            cntr += 1\n",
        "            cell = self.gridworld.current_cell\n",
        "            action = self.choose_action(cell)\n",
        "            reward = self.gridworld.reward(cell, action)\n",
        "            next_cell = self.gridworld.transition(cell, action)\n",
        "            # update the q-table \n",
        "            self.update(cell, action, reward, next_cell)\n",
        "            # add the reward to the last element in sum_rewards\n",
        "            self.sum_rewards[-1] += reward\n",
        "\n",
        "        self.episode += 1\n",
        "        self.anneal_epsilon\n",
        "\n",
        "    \n",
        "    def trajectory(self):\n",
        "        self.gridworld.reset()\n",
        "        self.path = []\n",
        "        sum_rewards = 0\n",
        "        itr = 0\n",
        "        while not self.gridworld.in_terminal() and itr < 20:\n",
        "            r, c = self.gridworld.current_cell\n",
        "            action = np.argmax(self.q_table[:, r, c])\n",
        "            sum_rewards += self.gridworld.reward((r, c), action)\n",
        "            self.gridworld.transition((r, c), action)\n",
        "            itr += 1\n",
        "            #print(itr)\n",
        "            self.path.append((r, c))\n",
        "        return sum_rewards\n",
        "\n",
        "    def is_learning_finished(self):  # depands on the number of episodes\n",
        "        return self.episode > self.episodes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LDTD4cQMk_Ag",
        "colab": {}
      },
      "source": [
        "class Sarsa:\n",
        "    \n",
        "    def __init__(self, gridworld, gamma, alpha, episodes):\n",
        "        self.gridworld = gridworld\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.episodes = episodes\n",
        "        # create table\n",
        "        size = gridworld.size\n",
        "        # create a numpy matrix for storing the q-values for each actions and states\n",
        "        self.q_table =  self.q_table = np.zeros((4,) + size) \n",
        "        # epsilon greedy\n",
        "        self.eps = 0.9\n",
        "        self.episode = 0\n",
        "        # preformance summary\n",
        "        self.sum_rewards = []\n",
        "        self.path = []\n",
        "    \n",
        "    def update(self, cell, action, reward, next_cell, next_action):\n",
        "        # the update rule for sarsa learning\n",
        "        r_t, c_t = cell  # current state\n",
        "        r_tp1, c_tp1 = next_cell  # next state\n",
        "        # update rule \n",
        "        q_current_step = self.q_table[action, r_t, c_t] \n",
        "        q_next_step = self.q_table[next_action, r_tp1, c_tp1]\n",
        "        error_term = reward + self.gamma * q_next_step - q_current_step\n",
        "        self.q_table[action, r_t, c_t] = q_current_step + self.alpha * (error_term)\n",
        "    \n",
        "    def choose_action(self, cell):\n",
        "        r, c = cell\n",
        "        # choose the next action accroding to epsilon-greedy \n",
        "        if np.random.random() > (1 - self.eps):\n",
        "            action = np.argmax(self.q_table[:, r, c])\n",
        "        else:\n",
        "            action = np.random.randint(low=0, high=4)\n",
        "        return action\n",
        "    \n",
        "    def anneal_epsilon(self):\n",
        "        # 1.5 - anneal earlier then the last episode\n",
        "        self.eps = max(0, self.eps * (1 - self.episode / self.episodes * 1.5))\n",
        "    \n",
        "    def one_episode(self):  # plays an episode\n",
        "\n",
        "        # Is it the first step of the episode?\n",
        "        first_step = True\n",
        "        cntr = 0\n",
        "        self.gridworld.reset()\n",
        "        self.sum_rewards.append(0)\n",
        "\n",
        "        while not self.gridworld.in_terminal() and cntr < 5000:\n",
        "            cntr += 1\n",
        "            cell = self.gridworld.current_cell\n",
        "\n",
        "            # ----- choose the action -----\n",
        "            if first_step == True:\n",
        "                action = self.choose_action(cell)\n",
        "                first_step = False\n",
        "            else:\n",
        "                # ensures to take the action with which we updated the\n",
        "                # q-table in the last round of the loop\n",
        "                action = next_action\n",
        "\n",
        "            # get the reward \n",
        "            reward = self.gridworld.reward(cell, action)\n",
        "            # make one transition and store\n",
        "            next_cell = self.gridworld.transition(cell, action)\n",
        "            # update the q-table \n",
        "            next_action = self.choose_action(next_cell)\n",
        "            self.update(cell, action, reward, next_cell, next_action)\n",
        "            # add the reward to the last element in sum_rewards \n",
        "            self.sum_rewards[-1] += reward\n",
        "\n",
        "        self.episode += 1\n",
        "        self.anneal_epsilon\n",
        "    \n",
        "    def trajectory(self):\n",
        "        self.gridworld.reset()\n",
        "        self.path = []\n",
        "        sum_rewards = 0\n",
        "        itr = 0\n",
        "        while not self.gridworld.in_terminal() and itr < 20:\n",
        "            r, c = self.gridworld.current_cell\n",
        "            action = np.argmax(self.q_table[:, r, c])\n",
        "            sum_rewards += self.gridworld.reward((r, c), action)\n",
        "            self.gridworld.transition((r, c), action)\n",
        "            itr += 1\n",
        "            self.path.append((r, c))\n",
        "        return sum_rewards\n",
        "\n",
        "    def is_learning_finished(self):\n",
        "        return self.episode > self.episodes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nx7aZfyrk_Aj",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(ql):\n",
        "    values = ql.sum_rewards\n",
        "    x = list(range(len(values)))\n",
        "    y = values\n",
        "    plt.plot(x, y, 'ro')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hGrKAqpulbOA"
      },
      "source": [
        "**Q-Learner**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FurCM9MDk_An",
        "outputId": "824e2e04-f3ec-442e-8afa-a465e92fa14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# grid world parameters\n",
        "size = (6, 6)\n",
        "start_cell = (0, 0)\n",
        "obstacles = [(3, 3)]\n",
        "terminating_state = (3, 5)\n",
        "# q learning parameters\n",
        "gamma = 0.9\n",
        "alpha = 0.1\n",
        "episodes = 220\n",
        "\n",
        "gw = GridWorld(size, start_cell, obstacles, terminating_state)\n",
        "solver = QLearning(gw, gamma, alpha, episodes)  # ----- try both of them -----\n",
        "#solver = Sarsa(gw, gamma, alpha, episodes)\n",
        "\n",
        "while not solver.is_learning_finished():\n",
        "    solver.one_episode()\n",
        "    sum_rewards = solver.sum_rewards[-1]\n",
        "    #print(sum_rewards)\n",
        "\n",
        "sum_rewards = solver.trajectory()\n",
        "print(sum_rewards)\n",
        "plot_learning_curve(solver)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD6CAYAAABJTke4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQmQgr+ISIAU/EVEAvT/PJD0TRrQ/0wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OpsiNTkelhfJ"
      },
      "source": [
        "**SARSA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjv58DBYlnwI",
        "outputId": "d3a60175-5fcf-4a3a-8722-50b6621e2d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# grid world parameters\n",
        "size = (6, 6)\n",
        "start_cell = (0, 0)\n",
        "obstacles = [(3, 3)]\n",
        "terminating_state = (3, 5)\n",
        "# q learning parameters\n",
        "gamma = 0.9\n",
        "alpha = 0.1\n",
        "episodes = 250\n",
        "\n",
        "gw = GridWorld(size, start_cell, obstacles, terminating_state)\n",
        "#solver = QLearning(gw, gamma, alpha, episodes)  # ----- try both of them -----\n",
        "solver = Sarsa(gw, gamma, alpha, episodes)\n",
        "\n",
        "while not solver.is_learning_finished():\n",
        "    solver.one_episode()\n",
        "    sum_rewards = solver.sum_rewards[-1]\n",
        "    #print(sum_rewards)\n",
        "\n",
        "sum_rewards = solver.trajectory()\n",
        "print(sum_rewards)\n",
        "plot_learning_curve(solver)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD5CAYAAADP2jUWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAZBklEQVR4nO3dbYwdV33H8d9/1zjKJlTAOoLUjncN\ncis5LaLJKgWJIlXQxokqDEhIRlagalUrJpFaJFTF8hveWGqpqFTUQLWlkQBva0VtaSyhEAiqyqtA\n1m1w7KSGzYMdWy6YIJVKRqFJ/n0xM/Xs9Tw/3Ln3nu9HGu3u3Nl7z5m59zdnzpyZa+4uAEBY5oYu\nAABg/Ah/AAgQ4Q8AASL8ASBAhD8ABIjwB4AAbRnqhc1sr6S/kjQv6Uvu/mdFy2/bts2Xl5fHUTQA\nmAknT578ibvflPXYIOFvZvOSHpT0O5IuSHrSzE64+zN5/7O8vKz19fVxFREApp6Znct7bKhunzsk\nbbj78+7+C0nHJe0bqCwAEJyhwn+7pJdSf1+I5wEAxmCiT/ia2UEzWzez9cuXLw9dHACYGUOF/0VJ\nt6T+3hHP28TdV919xd1Xbrop85wFAKCBocL/SUm7zWyXmW2VtF/SiYHKAgDBGST83f1VSfdLekzS\ns5IedvczQ5QFE2ptTVpelubmpG3bomluLpq3tlb/OZaXpU9+MvppJm3ZEv1Mnm902aqvMQ5ra1H9\nza5O27ZdW8a2daiyzuu+RrJ81jqvs0yVMqe3cVb5ssqeV+fk93SZ0mXLey81nT/E+87dp2K6/fbb\nHYE4dsx9YcFdyp4WFqJl2jxHenrDG9y3bq3/GuNw7FhUvqxyb916tYxZ9V1YcD90yH1pyd0s+plX\npyrr/NCh7Ndo8pzJ8y0uVtvOx45dW48q2zh5jqxls7b70FOdbVaBpHXPydTBQ73qNJHhn/WGHOf/\nT6q29VpaKv+QLC21f44qr3Hs2OaAWly8GiZZdcxbvuk6KqvH4mLxcmbXBt7i4rUhOjfXfD3Nz2/+\nmTxvF9ugaKpa5sXFdvWbhOnGGxvlA+Hfh7yWVtUN1Pb/y557qJ1KF/UaDay8UGv7HFWmrFb3/Hz2\nkcKhQ9nLp1vodddRlXocOtSufklodzlVPepiqj6Nvo8qIPz7kNeqKWuRdvX/ecqCpahl2sVOo0q9\nyl6nSosxafHmPV/frc6sqah1ma5/Xtnm56M6LC4Wd4eMTl3t6Ma5PpiaTTXzgfDvQ94HrqxF2tX/\nu9cLveTxvJZp3f7cpvWq0uqt0pebtILylr3hhur9uX21fvO267jCelJ3CkzttmkNhH8f3SBDt/zr\nnNBM3jRNWsOjLfai/uxjx/JDNHmevBbtaL1HXytrqhLYSetztF96tH+6Tku7yTTkEQnT7Ey0/Gto\n0wed3mkkh+JJiJa1lLP+V7oaOouL+f3GVbpl6rZUk/+r+2ZLt9jzRp0sLmavj9H1UqVvus5IjqZT\n1vbvu5X8/vf3U5++yr11a1TmPtfJNEzJe6WP9Zz3eSraJvT519C0hV116FveiI8qH/TRkRdFJwyL\nwrXqG7hJq3Nxsdr/5X045uevhnnVD9DCwnha4lXeJ11NXYVH3fMBTaa5uXbvty7XWR+he8MN0TRa\n5/T6Hf1MF42mKhuyWjQVNeLSdc8bNVYi7PAvWrFF2gw3rBMkVU4Elr1Jiuo4ulOq09roYhx0sp4n\nsbsjveOehLCrMo2rnH2fAymb+mpxN+3yzWvQ3Xhj/WsPsuqaVfcOhBv+RW+espZ/m+GGdd6wfZ0I\nzKtf1f7trlqYSTm6rFtfQxOTI7midZI8PkQ4Vj0KazvV3Vbp9VbUrVllu1ZtcbfZzk2vxymrX/qC\nsqrds+lzQT0MzQ43/IsO1cpWcNWWf9thhn20/Kv0DR47Vl6utoGd/qA1+RCPvn6dcwdNpmRbVD1P\nVPdIqot12fe5ibrPX9SIKhoAUPReGX2OrG3RpmFS56Rp3dfPGrhQdi6sR+GGf9Eb2b14j9vmcveq\nh+ZZQxzr9Pkn9avSN5hV16IPUNPRQXnlaHoCN6lb1cPqNqNq0kdhVVtjWSOgmu6c8oanptflJHWf\njW6bup/B0RFXebK2RdHzJoMsqmznMnXXd9ZzZx05jOniy3DDv2zMe5Xx5nmjfaqMqS8b7TM6L+l7\nLhvtk/7g5ZW9yvKHDhV3i+WtoyonuLJaV6PrJH3SreoFUlXvBVO0/euUuak6LdM6F8C1GQWVdKvk\nreulpeIL0NLdO2Xvv7IdcNt1XWUgR9vh1O7dHgkNINzwz/qgJCNsuth4TS/UansoWOVNXSUkkp1N\n0Qd5NIzqnHBMl6VKK7rKBWJFr5d1z5qqZe3iEHx051alz7urPugqU9LdWXQLiiqNorJGT9mOr6t1\n3eRiwbqvnVfXxcVeT9R2Jdzwd6//gezikLBsB1LWIm16Mjpd9qrDM0fXUdnhaNXWdBI0dT6AZeuz\n6LXzdmB5h9wd3jnx/9dh3YZGMgy2rao7uaKWfdntMtKKWsNVGhxdBWSV923bk6lF798eT9R2Jezw\nT2szfDNL05ZF2aFk02Go6bJXOVwtq2te11XVqahVmvXaZUchk3wIXrRNuriVR5myRk7ZCeMuGj1l\nRyFd1necug75Me40CP9EWXi0OQSvsyHbtvzbHJpXrWubvuUq02gQZL1ecgFN1ToNGTZFodpF33Nd\nee/LLsqS9/6bpJ1xG32GcxddUTUQ/omyE1BVN0Afh5J13whNTgxWGZ2RqBO0TYYfjgZBUXdEWYu2\n6rC7PrUdXDAuXZUl6/1X9J6pe7vzobpT+t5WY24IEP6JLjZs1x8eqb/hX20+RFUDve5J4Lz1VfX1\n8r6MZOhwLStDX4HW5Hn7LEvW+6DOrQmG3pZ9h/M4ugBTCP+0tm/8ce25+/iAdn1id3R0UfLcZX39\ndU72Vl3XkxCCTZ+vzf8NvdPLKtM0fL7y9B3OtPwHDP+2xnXyrssPdd7wu6LnLOvzr/u/XZ5j6GJd\nT0pwtinH0EHZhzG3jK/R9zqlz3+Kw38cH7guX6MsVIueM2u0T9UWXRct8T778iclONuUY+ig7MPQ\n22Uc4cxonykN/3G8Obr8UJd1p/QZFH2OsW6r7jru6wPbZlsPHZR9mIQjsikYv18V4d+1vt8cXX6o\ny06k9hUUfY4q6UKdddxnILXZ1pMQlH2YofAdGuE/bYo+1HU/GE2G33Xx4Zv0VmmV6woSfdalbYAT\nlChA+E+jrA91naBIDyXNav0X3f2zi9bkNPRHl11RnOi7LgQ4ekL4T7qqH/6qLdC8Vm2ybJMhnul7\nv1Qx6S1/9+plnIa6ABmKwn9OGNbamnTwoHTuXBQp585Ff6+tbV5meTl6LMv585v/PnJEunJl8zx3\naWlJevFF6cCB/PKMPlfi5Zc3l6nM0aPSwsLmeQsL0fxJkVfX0fnTUBegrry9wqRNE9/yb3roXtaq\nrDL+fbQF2scIkiYt3SG6M7q4kC3r6wTpmsEUEt0+PWvTT14W1GVDNbNep+0IkrzXatLHPc7QrLsd\nquxYZ2H0DIJF+PetrLXcpPWZBHXRUM2852570rari6vGPRSxyU6vym0p6NvHlCL866rbWm1zq+iy\ngMwLtOTLUrqqQ50yVTXuE6VtR+VMwwgloAbCv44mwVflpmRVW5+jQX3sWH4o9dki7aK7Ztxh2nZn\nw6gezBjCv46mXQdlfcdtAq/Kc07iCclxh2kXF0zN4hWzCBbhX0dRa7Wshd605V+myYigSQitIcrV\nxf2EJm0nCjRE+NdRdJFT069OHO2frxowRVfpVjkvMAndFYQpMJhBwl/SZyRdlPRUPN2deuywpA1J\nZyXdWeX5Bu3zLxtxU/a/6fvFVG0N17lKlxOVADIMGf6fzpi/R9L3JV0naZek5yTNlz3fIKN9yoI/\nK2DLWrp93FJgklv+AAZTFP5D3N5hn6Tj7v6Ku7+g6AjgjgHKsVlyC4W5uej2CEePRrdDiHZY+Xbu\n3Pz3gQPRLRRefz37VgpVbylQdTmJ2w8AqK3v8L/fzE6Z2UNm9uZ43nZJL6WWuRDPG07W/XXuuSf/\nXjqJJgE7urPIm191OSnawayuRjsrs+jn6mrxPXwABK1V+JvZ42Z2OmPaJ+mLkt4h6V2SLkn6XIPn\nP2hm62a2fvny5TZFLZZ3I7Qii4vS9ddHO4nl5eo3PavaSq/bmi874gCAtLz+oC4nScuSTse/H5Z0\nOPXYY5LeU/Ycvfb5F/XrZ42yOXRoPF/AEdJImZDqCoyJCvr8zctauA2Z2c3ufin+/VOSftPd95vZ\nrZL+XlE//y9L+rak3e7+WtHzrays+Pr6ei9lLbxdshR1o5w/H3W5HD0aHSlkLZ/cMhn1JN1u6aOv\nhQW6roCWzOyku69kPdZnn/9nzexpMzsl6bclfUqS3P2MpIclPSPpG5LuKwv+3h09GvWVZ0kCPd2d\nUudkbB3pk851upKmXVa325Ur0XwAvegt/N39Hnf/dXd/p7t/MDkKiB876u7vcPdfdfdH+ypDrtGQ\nlaR77712B5DXx17nZGzea44Ge5UvdZlVfe1MAeTL6w+atKmzPv8uvhy9i/vGV706OISx+iHXHeiR\nhujz71pnff55/ft1++vX1qJuifS5gLz+6SqvOTeXPcLILOpymmX0+QO9KOrzDy/8hwjZKq/Z1U5p\nWtXZmQKoZKgTvpOpSX/9OF4z9Kt0uU4BGKvwwn+IkK3ymlylC2CMwgv/IUK26mvS+gUwJuH1+QNA\nIOjzBwBsQvgDQIAI/1kT6i0iANQSTvi3CcVpCdSQbxEBoJYwTvi2uYJ0mq4+Df1CMQCbcIVvm1Cc\npkAN+RYRAK7BaJ+8u0OeO1felTNNd5wc4uplAFMpjPAvCr+yvvG2gTrO8wWh3yICQGVhhH9WKI7K\n+/KQNoE67hOw3CICQEVh9PlLm+8amVfnvL7xpnecnKbzBQBmDid8R40rlDkBC2BAnPAdNa6+cU7A\nAphQYYb/uPrGOQELYEKFGf7SeG6fPE0nYKflKmYAndgydAFm3oEDkxn2aaNXMSejkqTJLzuARsJt\n+eOqI0c2375Cyh/6CmAmEP6YrquYAXSC8O/StPabMyoJCA7h35Vpvp0yo5KA4BD+XZnmfvNpGpUE\noBNhXuHbB67mBTBhuMJ3HOg3BzBFCP+u0G8OYIoQ/l2h3xzAFOEK3y5Nw9W8ACBa/gAQJMIfAAJE\n+ANAgFqFv5l91MzOmNnrZrYy8thhM9sws7Nmdmdq/t543oaZPdDm9QEAzbRt+Z+W9BFJ30nPNLM9\nkvZLulXSXklfMLN5M5uX9KCkuyTtkfSxeFkAwBi1Gu3j7s9KkpmNPrRP0nF3f0XSC2a2IemO+LEN\nd38+/r/j8bLPtCkHAKCevvr8t0t6KfX3hXhe3nwAwBiVtvzN7HFJb8t46Ii7P9J9kTa99kFJByVp\nJ7dJAIDOlIa/u3+gwfNelHRL6u8d8TwVzM967VVJq1J0Y7cG5QAAZOir2+eEpP1mdp2Z7ZK0W9L3\nJD0pabeZ7TKzrYpOCp/oqQwAgBxth3p+2MwuSHqPpK+b2WOS5O5nJD2s6ETuNyTd5+6vufurku6X\n9JikZyU9HC87rGn9Bi4AaIj7+SffwJX+IpaFBW7KBmDqcT//ItP8DVwA0BDhf/58vfkAMAMIf76B\nC0CACH++gQtAgAj/0W/gWlyUrr9euuceRv4AmFmEvxTtAF58UfrqV6Wf/1x6+WXJXTp3LhoJxA4A\nwIwh/NMY+QMgEIR/GiN/AASC8E9j5A+AQBD+aYz8ARAIwj9tdOTP0hK3eQAwk1p9k9dMOnCAsAcw\n82j5A0CACH8ACBDhDwABIvwBIECEPwAEiPAHgAAR/gAQIMIfAAJE+ANAgAh/AAgQ4Q8AASL8ASBA\nhD8ABIjwB4AAEf4AECDCHwACRPgDQIAIfwAIEOEPAAEi/AEgQIQ/AASI8AeAABH+ABCgVuFvZh81\nszNm9rqZraTmL5vZz83sqXj6m9Rjt5vZ02a2YWafNzNrUwYAQH1tW/6nJX1E0ncyHnvO3d8VT/em\n5n9R0h9J2h1Pe1uWAQBQU6vwd/dn3f1s1eXN7GZJv+TuT7i7S/qKpA+1KQMAoL4++/x3mdl/mNm/\nmdlvxfO2S7qQWuZCPA8AMEZbyhYws8clvS3joSPu/kjOv12StNPdXzaz2yX9i5ndWrdwZnZQ0kFJ\n2rlzZ91/BwDkKA1/d/9A3Sd191ckvRL/ftLMnpP0K5IuStqRWnRHPC/veVYlrUrSysqK1y0HACBb\nL90+ZnaTmc3Hv79d0Ynd5939kqSfmdm741E+H5eUd/QAAOhJ26GeHzazC5LeI+nrZvZY/ND7JJ0y\ns6ck/aOke939p/Fjn5T0JUkbkp6T9GibMgAA6rNo0M3kW1lZ8fX19aGLAQBTw8xOuvtK1mNc4QsA\nASL8ASBAhD8ABIjwB4AAEf4AECDCHwACRPgDQIAIfwAIEOEPAAEi/AEgQIQ/AASI8AeAABH+ABAg\nwh8AAkT4A0CACH8ACBDhDwABIvwBIECEPwAEiPAHgAAR/gAQIMIfAAJE+ANAgAh/AAgQ4Q8AASL8\nASBAhD8ABIjwB4AAEf4AECDCHwACRPgDQIAIfwAIEOEPAAEi/AEgQIQ/AASoVfib2V+Y2X+a2Skz\n+5qZvSn12GEz2zCzs2Z2Z2r+3njehpk90Ob1AQDNtG35f0vSr7n7OyX9QNJhSTKzPZL2S7pV0l5J\nXzCzeTObl/SgpLsk7ZH0sXhZAMAYtQp/d/+mu78a//mEpB3x7/skHXf3V9z9BUkbku6Ipw13f97d\nfyHpeLwsAGCMuuzz/wNJj8a/b5f0UuqxC/G8vPkAgDHaUraAmT0u6W0ZDx1x90fiZY5IelXSWpeF\nM7ODkg5K0s6dO7t8agAIWmn4u/sHih43s9+X9HuS3u/uHs++KOmW1GI74nkqmJ/12quSViVpZWXF\n85YDANTTdrTPXkl/KumD7n4l9dAJSfvN7Doz2yVpt6TvSXpS0m4z22VmWxWdFD7RpgwAgPpKW/4l\n/lrSdZK+ZWaS9IS73+vuZ8zsYUnPKOoOus/dX5MkM7tf0mOS5iU95O5nWpYBAFCTXe2pmWwrKyu+\nvr4+dDEAYGqY2Ul3X8l6jCt8ASBAhD8ABIjwB4AAEf4AECDCHwACRPgDQIAIfwAIEOEPAAEi/AEg\nQIQ/AASI8AeAABH+ABAgwh8AAkT4A0CACH8ACBDhDwABIvwBIECEPwAEiPAHgAAR/gAQoNkO/7U1\naXlZmpuLfq6tDV0iAJgIW4YuQG/W1qSDB6UrV6K/z52L/pakAweGKxcATIDZbfkfOXI1+BNXrkTz\nASBwsxv+58/Xmw8AAZnd8N+5s958AAjI7Ib/0aPSwsLmeQsL0XwACNzshv+BA9LqqrS0JJlFP1dX\nOdkLAJrl0T5SFPSEPQBcY3Zb/gCAXIQ/AASI8AeAABH+ABAgwh8AAmTuPnQZKjGzy5LONfz3bZJ+\n0mFxpgF1nn2h1VeiznUtuftNWQ9MTfi3YWbr7r4ydDnGiTrPvtDqK1HnLtHtAwABIvwBIEChhP/q\n0AUYAHWefaHVV6LOnQmizx8AsFkoLX8AQMpMh7+Z7TWzs2a2YWYPDF2evpjZi2b2tJk9ZWbr8by3\nmNm3zOyH8c83D13ONszsITP7sZmdTs3LrKNFPh9v91NmdttwJW8up86fMbOL8bZ+yszuTj12OK7z\nWTO7c5hSt2Nmt5jZv5rZM2Z2xsz+OJ4/k9u6oL79b2d3n8lJ0ryk5yS9XdJWSd+XtGfocvVU1xcl\nbRuZ91lJD8S/PyDpz4cuZ8s6vk/SbZJOl9VR0t2SHpVkkt4t6btDl7/DOn9G0qczlt0Tv8evk7Qr\nfu/PD12HBnW+WdJt8e9vlPSDuG4zua0L6tv7dp7llv8dkjbc/Xl3/4Wk45L2DVymcdon6cvx71+W\n9KEBy9Kau39H0k9HZufVcZ+kr3jkCUlvMrObx1PS7uTUOc8+Scfd/RV3f0HShqLPwFRx90vu/u/x\n7/8j6VlJ2zWj27qgvnk6286zHP7bJb2U+vuCilfqNHNJ3zSzk2Z2MJ73Vne/FP/+X5LeOkzRepVX\nx1nf9vfHXRwPpbrzZq7OZrYs6TckfVcBbOuR+ko9b+dZDv+QvNfdb5N0l6T7zOx96Qc9Ol6c6WFd\nIdQx9kVJ75D0LkmXJH1u2OL0w8xulPRPkv7E3X+WfmwWt3VGfXvfzrMc/hcl3ZL6e0c8b+a4+8X4\n548lfU3RYeCPksPf+OePhythb/LqOLPb3t1/5O6vufvrkv5WVw/5Z6bOZvYGRUG45u7/HM+e2W2d\nVd9xbOdZDv8nJe02s11mtlXSfkknBi5T58zsBjN7Y/K7pN+VdFpRXT8RL/YJSY8MU8Je5dXxhKSP\nxyNB3i3pv1NdBlNtpD/7w4q2tRTVeb+ZXWdmuyTtlvS9cZevLTMzSX8n6Vl3/8vUQzO5rfPqO5bt\nPPTZ7p7PpN+t6Oz5c5KODF2enur4dkVn/78v6UxST0mLkr4t6YeSHpf0lqHL2rKe/6Do8Pd/FfVz\n/mFeHRWN/Hgw3u5PS1oZuvwd1vmrcZ1OxUFwc2r5I3Gdz0q6a+jyN6zzexV16ZyS9FQ83T2r27qg\nvr1vZ67wBYAAzXK3DwAgB+EPAAEi/AEgQIQ/AASI8AeAABH+ABAgwh8AAkT4A0CA/g+J726qzh+a\nrgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}