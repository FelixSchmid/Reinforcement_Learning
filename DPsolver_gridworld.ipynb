{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPsolver_gridworld.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelixSchmid/Reinforcement_Learning/blob/master/DPsolver_gridworld.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nzUfYGijaH0Q",
        "colab": {}
      },
      "source": [
        "# importing the necessary libraries\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZlBrYGuaH0X"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=18q7KL4aV6McMtaid_1Let2aGkw6d4QYn\" width=45%>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HhCVLjUpaH0Z",
        "colab": {}
      },
      "source": [
        "class GridWorld:\n",
        "    \"\"\" \n",
        "    The environment: (see image)\n",
        "    * cells: the agent can step on a cell. There is exactly one cell to start from.\n",
        "    This is the top left corner. There is one terminal cell where the walking ends, \n",
        "    the agent can not leave it (blue).\n",
        "    * obstacles: there are cells where the agent can not step. (gray)\n",
        "    * agent: it can move from one cell to an other neighboring cell. \n",
        "    Possible directions: up, down, left, right. Each transition happens with probability 1.\n",
        "    * reward: after each transition the agent receives -1 point. In the terminal cell, no reward\n",
        "    received anymore.\n",
        "    \"\"\"\n",
        "    def __init__(self, size, start_cell, obstacles, terminating_state):\n",
        "        self.size = size\n",
        "        self.start = start_cell\n",
        "        self.obstacles = obstacles\n",
        "        self.termin = terminating_state\n",
        "        self.current_cell = self.start\n",
        "    \n",
        "    def reset(self):\n",
        "        self.current_cell = self.start\n",
        "    \n",
        "    def transition(self, cell, action):\n",
        "        # cell = (row, column) indices\n",
        "        # action: 0 left, 1 up, 2 right, 3 down\n",
        "        # returns: What will be the next state\n",
        "\n",
        "        r_current = cell[0]\n",
        "        c_current = cell[1]\n",
        "        \n",
        "        # left\n",
        "        if action == 0:\n",
        "          cell = (r_current,c_current-1)\n",
        "        # up\n",
        "        if action == 1:\n",
        "          cell = (r_current-1,c_current)\n",
        "        # right\n",
        "        if action == 2:\n",
        "          cell = (r_current,c_current+1)\n",
        "        # down\n",
        "        if action == 3:\n",
        "          cell = (r_current+1,c_current)\n",
        "\n",
        "        if (cell[0], cell[1]) in self.obstacles:\n",
        "          # undo step if we hit an obst.\n",
        "          cell = (r_current,c_current)\n",
        "\n",
        "        if cell[0] < 0 \\\n",
        "             or cell[0] > self.size[0] -1 \\\n",
        "             or cell[1] < 0  \\\n",
        "             or cell[1] > self.size[1] -1 : \n",
        "          # undo steps if we left the board\n",
        "          cell = (r_current, c_current)\n",
        "        \n",
        "        # update the current_cell the step\n",
        "        self.current_cell = cell\n",
        "        \n",
        "        return cell\n",
        "\n",
        "\n",
        "    def reward(self, cell, action):\n",
        "        # ----- RETURN REWARD -----\n",
        "        # -1 if not in the terminal state\n",
        "        cell_state = cell\n",
        "        if self.transition(cell, action) != self.termin:\n",
        "          reward = -1\n",
        "        else:\n",
        "          reward = 0\n",
        "        # we only want to know the reward of a pot. transition.\n",
        "        # so, we undo the action which is done within def transition that we call\n",
        "        # for doing the transition, we need to call transition alone.\n",
        "        # probably there is a more elegant solution,\n",
        "        # but it works this way\n",
        "        self.current_cell = cell_state\n",
        "        return reward\n",
        "\n",
        "    def in_terminal(self):\n",
        "        return self.current_cell == self.termin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dP7JvLiUaH0d",
        "colab": {}
      },
      "source": [
        "class DPsolver:\n",
        "    \"\"\"\n",
        "    This solver is based on the Bellman-equation and it is \n",
        "    solved by iteratively.\n",
        "    The action-value is used to represent the utility of the \n",
        "    actions and states.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gridworld, gamma, iterations):\n",
        "        # setting parametes according to the input parameters\n",
        "        self.gridworld = gridworld\n",
        "        self.gamma = gamma\n",
        "        self.iterations = iterations\n",
        "        size = gridworld.size\n",
        "        # initialize accumulaters\n",
        "        self.cntr = 0\n",
        "        self.sum_rewards = []\n",
        "        self.path = []\n",
        "        # initialize the table for Q-function \n",
        "        self.q_table = np.zeros((4,) + size)\n",
        "\n",
        "    def step(self):\n",
        "        rows, cols = self.gridworld.size  # ask for the size of the grid\n",
        "\n",
        "        for r in range(rows):\n",
        "            for c in range(cols):\n",
        "                for action in range(4):\n",
        "                    # get the reward \n",
        "                    cell_to_update = (r,c)\n",
        "                    reward = self.gridworld.reward(cell_to_update, action)\n",
        "                    # next step\n",
        "                    cell_next = self.gridworld.transition(cell_to_update,action)\n",
        "                    r2, c2 = cell_next\n",
        "                    # policy: always take the next step with that is most valuable\n",
        "                    next_rewards = max(self.q_table[:, r2, c2])\n",
        "                    # compute Q-value and update\n",
        "                    self.q_table[action, r, c] =  reward + self.gamma * next_rewards\n",
        "\n",
        "        # increase the counter\n",
        "        self.cntr += 1\n",
        "        # add the return to the sum_rewards list\n",
        "        self.sum_rewards.append(self.trajectory())\n",
        "\n",
        "    def trajectory(self):\n",
        "        # reset the gridworld\n",
        "        self.gridworld.reset()\n",
        "        # calculate the return along a trajectory followed by the current policy\n",
        "        # when started from the start_cell\n",
        "        self.path = []\n",
        "        sum_rewards = 0\n",
        "        i = 0\n",
        "        while not self.gridworld.in_terminal() and i < 40 :\n",
        "            r, c = self.gridworld.current_cell\n",
        "            # take action with most value\n",
        "            action = np.argmax(self.q_table[:, r, c])\n",
        "            reward = self.gridworld.reward((r, c), action)\n",
        "            # do the step\n",
        "            self.gridworld.transition((r, c), action)\n",
        "            # collect reward\n",
        "            sum_rewards += reward\n",
        "            i += 1\n",
        "            # collect path\n",
        "            self.path.append((r, c))\n",
        "        return sum_rewards\n",
        "\n",
        "    def is_learning_finished(self):\n",
        "        return self.cntr >= self.iterations\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "su8GzRdaaH0i",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(ql):\n",
        "    values = ql.sum_rewards\n",
        "    x = list(range(len(values)))\n",
        "    y = values\n",
        "    plt.title('Sum rewards')\n",
        "    plt.plot(x, y, 'ro')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G4t02O5-hxwD",
        "outputId": "18939c90-ec40-4693-f6b2-db1e08d1332f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "# grid world parameters\n",
        "size = (6, 6)\n",
        "start_cell = (0, 0)\n",
        "obstacles = [(3, 3)]\n",
        "terminating_state = (3, 5)\n",
        "# q learning parameters\n",
        "gamma = 0.9\n",
        "iterations = 8\n",
        "\n",
        "gw = GridWorld(size, start_cell, obstacles, terminating_state)\n",
        "solver = DPsolver(gw, gamma, iterations)\n",
        "\n",
        "while not solver.is_learning_finished():\n",
        "    solver.step()\n",
        "    sum_rewards = solver.sum_rewards[-1]\n",
        "    print(sum_rewards)\n",
        "\n",
        "sum_rewards = solver.trajectory()\n",
        "plot_learning_curve(solver)\n",
        "print(solver.path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-40\n",
            "-40\n",
            "-40\n",
            "-40\n",
            "-40\n",
            "-40\n",
            "-40\n",
            "-7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEICAYAAAC6fYRZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 5), (2, 5)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "idfbC1FyiW6f"
      },
      "source": [
        "For the initially defined problem the algorithm needs 8 iterations until it succesfully finds the shortest way. In the following, I made the problem a little bit more challenging and it took the algorithm 10 iterations to solve it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "flv-eWXwaH0m",
        "outputId": "3d94dd45-d08c-4da5-aa83-38f662a087dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "# same game with a bit more complicated task\n",
        "size = (6, 6)\n",
        "start_cell = (0, 0)\n",
        "obstacles = [(0, 1), (1, 1), (2, 2)]\n",
        "terminating_state = (0, 2)\n",
        "# q learning parameters\n",
        "gamma = 0.9\n",
        "iterations = 10\n",
        "\n",
        "gw = GridWorld(size, start_cell, obstacles, terminating_state)\n",
        "solver = DPsolver(gw, gamma, iterations)\n",
        "\n",
        "while not solver.is_learning_finished():\n",
        "    solver.step()\n",
        "print('Terminating state:')\n",
        "print(terminating_state)\n",
        "print('Path:')\n",
        "print(solver.path)\n",
        "print('Obstacles:')\n",
        "print(obstacles)\n",
        "plot_learning_curve(solver)\n",
        "print('sum rewards for the last iteration:')\n",
        "sum_rewards = solver.trajectory()\n",
        "print(sum_rewards)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Terminating state:\n",
            "(0, 2)\n",
            "Path:\n",
            "[(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (1, 3), (1, 2)]\n",
            "Obstacles:\n",
            "[(0, 1), (1, 1), (2, 2)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEICAYAAAC6fYRZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "sum rewards for the last iteration:\n",
            "-9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}